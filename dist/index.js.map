{"version":3,"file":"index.js","mappings":";;;;;;AAAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AChEA;AACA;;;;AEDA;AACA;AACA;AACA","sources":["../external node-commonjs \"child_process\"","../external node-commonjs \"fs\"","../external node-commonjs \"module\"","../external node-commonjs \"os\"","../external node-commonjs \"path\"",".././index.js","../webpack/bootstrap","../webpack/runtime/async module","../webpack/runtime/compat","../webpack/before-startup","../webpack/startup","../webpack/after-startup"],"sourcesContent":["module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"child_process\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"fs\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"module\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"os\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"path\");","import { createRequire } from 'module';\nimport fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { execSync } from 'child_process';\n\nconst require = createRequire(import.meta.url);\nconst core = require('@actions/core');\nconst github = require('@actions/github');\n\nfunction runCmd(cmd, options = {}) {\n  core.info(`$ ${cmd}`);\n  try {\n    execSync(cmd, { stdio: 'inherit', ...options });\n  } catch (err) {\n    throw new Error(`Command failed: ${cmd}`);\n  }\n}\n\nfunction readJson(filePath) {\n  const raw = fs.readFileSync(filePath, 'utf8');\n  return JSON.parse(raw);\n}\n\nfunction computeDelta(baseReport, headReport) {\n  function indexReport(report) {\n    const stacks = new Map();\n    for (const s of report.stacks || []) {\n      const itemMap = new Map();\n      for (const item of s.items || []) {\n        const key = `${item.service}|${item.logical_id}`;\n        itemMap.set(key, item);\n      }\n      stacks.set(s.name, {\n        name: s.name,\n        total: s.total_monthly_usd ?? 0,\n        items: itemMap,\n      });\n    }\n    const total =\n      report.grand_total_usd ??\n      Array.from(stacks.values()).reduce((sum, s) => sum + (s.total || 0), 0);\n    return { stacks, total };\n  }\n\n  const base = indexReport(baseReport);\n  const head = indexReport(headReport);\n\n  const stackNames = new Set([\n    ...base.stacks.keys(),\n    ...head.stacks.keys(),\n  ]);\n\n  const stacksDelta = [];\n  for (const stackName of stackNames) {\n    const baseStack = base.stacks.get(stackName);\n    const headStack = head.stacks.get(stackName);\n    const baseTotal = baseStack?.total ?? 0;\n    const headTotal = headStack?.total ?? 0;\n    const diff = headTotal - baseTotal;\n\n    const itemKeys = new Set([\n      ...(baseStack ? baseStack.items.keys() : []),\n      ...(headStack ? headStack.items.keys() : []),\n    ]);\n\n    const items = [];\n    for (const key of itemKeys) {\n      const baseItem = baseStack?.items.get(key);\n      const headItem = headStack?.items.get(key);\n      const baseVal = baseItem?.monthly_usd ?? 0;\n      const headVal = headItem?.monthly_usd ?? 0;\n      const itemDiff = headVal - baseVal;\n      if (itemDiff === 0) continue;\n      const [service, logicalId] = key.split('|');\n      items.push({\n        service,\n        logicalId,\n        cdkPath: headItem?.cdk_path || baseItem?.cdk_path || undefined,\n        base: baseVal,\n        head: headVal,\n        diff: itemDiff,\n        notes: headItem?.notes || baseItem?.notes || [],\n        stackName,\n      });\n    }\n\n    items.sort((a, b) => Math.abs(b.diff) - Math.abs(a.diff));\n\n    stacksDelta.push({\n      stackName,\n      base: baseTotal,\n      head: headTotal,\n      diff,\n      items,\n    });\n  }\n\n  stacksDelta.sort((a, b) => Math.abs(b.diff) - Math.abs(a.diff));\n\n  return {\n    total: {\n      base: base.total,\n      head: head.total,\n      diff: head.total - base.total,\n    },\n    stacks: stacksDelta,\n  };\n}\n\nfunction formatUsd(value) {\n  return `$${value.toFixed(2)}`;\n}\n\nfunction renderMarkdown(delta, commentTitle) {\n  const lines = [];\n  lines.push('<!-- cloudcostgh-comment -->');\n  lines.push(`## ${commentTitle}`);\n  lines.push('');\n\n  const total = delta.total;\n  lines.push('**Total monthly cost**');\n  lines.push('');\n  lines.push('|        | Base | Head | Δ |');\n  lines.push('|--------|------|------|---|');\n  lines.push(\n    `| Amount | ${formatUsd(total.base)} | ${formatUsd(\n      total.head,\n    )} | ${formatUsd(total.diff)} |`,\n  );\n  lines.push('');\n\n  const allItems = [];\n  for (const stack of delta.stacks) {\n    for (const item of stack.items) {\n      allItems.push(item);\n    }\n  }\n\n  allItems.sort((a, b) => Math.abs(b.diff) - Math.abs(a.diff));\n  const topItems = allItems.slice(0, 10);\n\n  if (topItems.length > 0) {\n    lines.push('**Top resource deltas**');\n    lines.push('');\n    lines.push('| Stack | Service | Logical ID | Base | Head | Δ |');\n    lines.push('|-------|---------|-----------|------|------|---|');\n    for (const item of topItems) {\n      lines.push(\n        `| ${item.stackName} | ${item.service} | ${item.logicalId} | ${formatUsd(\n          item.base,\n        )} | ${formatUsd(item.head)} | ${formatUsd(item.diff)} |`,\n      );\n    }\n    lines.push('');\n  }\n\n  return lines.join('\\n');\n}\n\nasync function upsertPrComment(octokit, commentBody, updateExisting, commentTitle) {\n  const context = github.context;\n  const { owner, repo } = context.repo;\n  const pull = context.payload.pull_request;\n  if (!pull) {\n    core.info('Not a pull_request event; skipping PR comment.');\n    return;\n  }\n  const issue_number = pull.number;\n\n  const marker = '<!-- cloudcostgh-comment -->';\n  const comments = await octokit.rest.issues.listComments({\n    owner,\n    repo,\n    issue_number,\n    per_page: 100,\n  });\n\n  const existing = comments.data.find((c) =>\n    c.body && c.body.includes(marker),\n  );\n\n  if (existing && updateExisting) {\n    core.info('Updating existing CloudCost comment.');\n    await octokit.rest.issues.updateComment({\n      owner,\n      repo,\n      comment_id: existing.id,\n      body: commentBody,\n    });\n  } else {\n    core.info('Creating new CloudCost comment.');\n    await octokit.rest.issues.createComment({\n      owner,\n      repo,\n      issue_number,\n      body: commentBody,\n    });\n  }\n}\n\nasync function main() {\n  try {\n    const backendUrl = 'https://cloudcost-action-api.vercel.app/';\n    const region = core.getInput('region') || 'us-east-1';\n    const usageProfile = core.getInput('usage_profile') || 'small';\n    const analyzerVersion = core.getInput('analyzer_version') || 'v0.1.0';\n    const commentTitle =\n      core.getInput('comment_title') || 'Cloud Cost Impact';\n    const updateExistingInput = core.getInput('update_existing_comment');\n    const updateExisting =\n      updateExistingInput === '' ? true : updateExistingInput !== 'false';\n    const enableUsageReportingInput = core.getInput('enable_usage_reporting');\n    const enableUsageReporting =\n      enableUsageReportingInput && enableUsageReportingInput !== 'false';\n    const githubToken = process.env.GITHUB_TOKEN;\n\n    if (!githubToken) {\n      core.setFailed('GITHUB_TOKEN environment variable is required to post PR comments.');\n      return;\n    }\n\n    const apiKeyInput = core.getInput('api_key');\n    const apiKey = apiKeyInput || process.env.CLOUDCOST_API_KEY;\n    if (!apiKey) {\n      core.setFailed(\n        'api_key input (or CLOUDCOST_API_KEY env) is required but not set.',\n      );\n      return;\n    }\n\n    const context = github.context;\n    const pull = context.payload.pull_request;\n    if (!pull) {\n      core.setFailed('This action must be run on a pull_request event.');\n      return;\n    }\n\n    const headSha = pull.head.sha;\n    const baseSha = pull.base.sha;\n\n    const tmpDir = process.env.RUNNER_TEMP || os.tmpdir();\n    const workDir = process.cwd();\n    const analyzerDir = path.join(tmpDir, 'cloudcost-analyzer');\n    const analyzerPath = path.join(analyzerDir, 'analyzer');\n    const headJson = path.join(tmpDir, 'cloudcost-head-report.json');\n    const baseJson = path.join(tmpDir, 'cloudcost-base-report.json');\n\n    fs.mkdirSync(analyzerDir, { recursive: true });\n\n    const analyzerUrl = `https://github.com/odrori1997/cloudcost-analyzer/archive/refs/tags/${analyzerVersion}.tar.gz`;\n    const archivePath = path.join(analyzerDir, 'analyzer.tar.gz');\n\n    core.info(`Downloading analyzer from ${analyzerUrl}`);\n    runCmd(`curl -sSL \"${analyzerUrl}\" -o \"${archivePath}\"`);\n    runCmd(`tar -xzf \"${archivePath}\" -C \"${analyzerDir}\"`);\n    runCmd(`chmod +x \"${analyzerPath}\"`);\n\n    const startTime = Date.now();\n\n    // Head analysis\n    core.startGroup('Analyze head commit');\n    runCmd('npx cdk synth --quiet', { cwd: workDir });\n    runCmd(\n      `\"${analyzerPath}\" ` +\n        `--cdk-out ./cdk.out ` +\n        `--region ${region} ` +\n        `--usage-profile ${usageProfile} ` +\n        `--out-json \"${headJson}\" ` +\n        `--out-md \"${path.join(tmpDir, 'cloudcost-head-report.md')}\" ` +\n        `--api-key \"${apiKey}\" ` +\n        `--backend-url \"${backendUrl}\"`,\n      { cwd: workDir },\n    );\n    core.endGroup();\n\n    // Base analysis\n    core.startGroup('Analyze base commit');\n    runCmd(`git checkout ${baseSha}`, { cwd: workDir });\n    runCmd('npx cdk synth --quiet', { cwd: workDir });\n    runCmd(\n      `\"${analyzerPath}\" ` +\n        `--cdk-out ./cdk.out ` +\n        `--region ${region} ` +\n        `--usage-profile ${usageProfile} ` +\n        `--out-json \"${baseJson}\" ` +\n        `--out-md \"${path.join(tmpDir, 'cloudcost-base-report.md')}\" ` +\n        `--api-key \"${apiKey}\" ` +\n        `--backend-url \"${backendUrl}\"`,\n      { cwd: workDir },\n    );\n    runCmd(`git checkout ${headSha}`, { cwd: workDir });\n    core.endGroup();\n\n    const baseReport = readJson(baseJson);\n    const headReport = readJson(headJson);\n    const delta = computeDelta(baseReport, headReport);\n    const markdown = renderMarkdown(delta, commentTitle);\n\n    core.setOutput('delta-json', JSON.stringify(delta));\n    core.setOutput('delta-md', markdown);\n    core.setOutput('head-total', delta.total.head);\n    core.setOutput('base-total', delta.total.base);\n    core.setOutput('delta-total', delta.total.diff);\n\n    const octokit = github.getOctokit(githubToken);\n    await upsertPrComment(octokit, markdown, updateExisting, commentTitle);\n\n    if (enableUsageReporting) {\n      const durationMs = Date.now() - startTime;\n      try {\n        core.startGroup('Send usage record');\n        const usageUrl = `${backendUrl.replace(/\\/$/, '')}/api/v1/usage`;\n        await fetch(usageUrl, {\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json',\n            Authorization: `Bearer ${apiKey}`,\n          },\n          body: JSON.stringify({\n            repo: context.repo.owner + '/' + context.repo.repo,\n            commit: headSha,\n            pr: pull.number,\n            duration_ms: durationMs,\n            head_total: delta.total.head,\n            base_total: delta.total.base,\n            delta_total: delta.total.diff,\n          }),\n        });\n        core.endGroup();\n      } catch (err) {\n        core.warning(`Failed to send usage record: ${err.message || err}`);\n      }\n    }\n  } catch (error) {\n    core.setFailed(error.message || String(error));\n  }\n}\n\nawait main();\n\n\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","var webpackQueues = typeof Symbol === \"function\" ? Symbol(\"webpack queues\") : \"__webpack_queues__\";\nvar webpackExports = typeof Symbol === \"function\" ? Symbol(\"webpack exports\") : \"__webpack_exports__\";\nvar webpackError = typeof Symbol === \"function\" ? Symbol(\"webpack error\") : \"__webpack_error__\";\nvar resolveQueue = (queue) => {\n\tif(queue && queue.d < 1) {\n\t\tqueue.d = 1;\n\t\tqueue.forEach((fn) => (fn.r--));\n\t\tqueue.forEach((fn) => (fn.r-- ? fn.r++ : fn()));\n\t}\n}\nvar wrapDeps = (deps) => (deps.map((dep) => {\n\tif(dep !== null && typeof dep === \"object\") {\n\t\tif(dep[webpackQueues]) return dep;\n\t\tif(dep.then) {\n\t\t\tvar queue = [];\n\t\t\tqueue.d = 0;\n\t\t\tdep.then((r) => {\n\t\t\t\tobj[webpackExports] = r;\n\t\t\t\tresolveQueue(queue);\n\t\t\t}, (e) => {\n\t\t\t\tobj[webpackError] = e;\n\t\t\t\tresolveQueue(queue);\n\t\t\t});\n\t\t\tvar obj = {};\n\t\t\tobj[webpackQueues] = (fn) => (fn(queue));\n\t\t\treturn obj;\n\t\t}\n\t}\n\tvar ret = {};\n\tret[webpackQueues] = x => {};\n\tret[webpackExports] = dep;\n\treturn ret;\n}));\n__webpack_require__.a = (module, body, hasAwait) => {\n\tvar queue;\n\thasAwait && ((queue = []).d = -1);\n\tvar depQueues = new Set();\n\tvar exports = module.exports;\n\tvar currentDeps;\n\tvar outerResolve;\n\tvar reject;\n\tvar promise = new Promise((resolve, rej) => {\n\t\treject = rej;\n\t\touterResolve = resolve;\n\t});\n\tpromise[webpackExports] = exports;\n\tpromise[webpackQueues] = (fn) => (queue && fn(queue), depQueues.forEach(fn), promise[\"catch\"](x => {}));\n\tmodule.exports = promise;\n\tbody((deps) => {\n\t\tcurrentDeps = wrapDeps(deps);\n\t\tvar fn;\n\t\tvar getResult = () => (currentDeps.map((d) => {\n\t\t\tif(d[webpackError]) throw d[webpackError];\n\t\t\treturn d[webpackExports];\n\t\t}))\n\t\tvar promise = new Promise((resolve) => {\n\t\t\tfn = () => (resolve(getResult));\n\t\t\tfn.r = 0;\n\t\t\tvar fnQueue = (q) => (q !== queue && !depQueues.has(q) && (depQueues.add(q), q && !q.d && (fn.r++, q.push(fn))));\n\t\t\tcurrentDeps.map((dep) => (dep[webpackQueues](fnQueue)));\n\t\t});\n\t\treturn fn.r ? promise : getResult();\n\t}, (err) => ((err ? reject(promise[webpackError] = err) : outerResolve(exports)), resolveQueue(queue)));\n\tqueue && queue.d < 0 && (queue.d = 0);\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = new URL('.', import.meta.url).pathname.slice(import.meta.url.match(/^file:\\/\\/\\/\\w:/) ? 1 : 0, -1) + \"/\";","","// startup\n// Load entry module and return exports\n// This entry module used 'module' so it can't be inlined\nvar __webpack_exports__ = __webpack_require__(483);\n",""],"names":[],"sourceRoot":""}